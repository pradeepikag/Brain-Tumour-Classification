{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ab85b94677c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(activation = 'relu',units=128))\n",
    "classifier.add(Dense(activation = 'sigmoid',units=1))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Desktop\\btd1_project\\Brain_tumor\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('C:/Users/hp/Desktop/btd1_project/Brain_tumor')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 2 classes.\n",
      "Found 7 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/hp/Desktop/btd1_project/Brain_tumor/train/',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/hp/Desktop/btd1_project/Brain_tumor/test/',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6987 - acc: 0.4545 - val_loss: 0.8402 - val_acc: 0.5714\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.9168 - acc: 0.5909 - val_loss: 0.6657 - val_acc: 0.5714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.6563 - acc: 0.5909 - val_loss: 0.7537 - val_acc: 0.4286\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.6964 - acc: 0.4091 - val_loss: 0.7674 - val_acc: 0.4286\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.6884 - acc: 0.4091 - val_loss: 0.7427 - val_acc: 0.4286\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.6684 - acc: 0.5909 - val_loss: 0.7156 - val_acc: 0.4286\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.6382 - acc: 0.8182 - val_loss: 0.6930 - val_acc: 0.4286\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.6294 - acc: 0.7273 - val_loss: 0.6802 - val_acc: 0.7143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.6530 - acc: 0.5909 - val_loss: 0.6763 - val_acc: 0.5714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.6421 - acc: 0.5909 - val_loss: 0.6772 - val_acc: 0.5714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.6126 - acc: 0.5909 - val_loss: 0.6828 - val_acc: 0.5714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.6050 - acc: 0.5909 - val_loss: 0.6959 - val_acc: 0.4286\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.6035 - acc: 0.6818 - val_loss: 0.7191 - val_acc: 0.5714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5848 - acc: 0.7273 - val_loss: 0.7478 - val_acc: 0.4286\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5882 - acc: 0.7273 - val_loss: 0.7745 - val_acc: 0.4286\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.5562 - acc: 0.8182 - val_loss: 0.7985 - val_acc: 0.4286\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6069 - acc: 0.6364 - val_loss: 0.7962 - val_acc: 0.5714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.5344 - acc: 0.8636 - val_loss: 0.8005 - val_acc: 0.5714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5335 - acc: 0.7727 - val_loss: 0.8174 - val_acc: 0.5714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5326 - acc: 0.7727 - val_loss: 0.8500 - val_acc: 0.5714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5267 - acc: 0.7727 - val_loss: 0.8969 - val_acc: 0.5714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4605 - acc: 0.8182 - val_loss: 0.9873 - val_acc: 0.4286\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4864 - acc: 0.7273 - val_loss: 1.0765 - val_acc: 0.4286\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4964 - acc: 0.8182 - val_loss: 1.1636 - val_acc: 0.4286\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.4719 - acc: 0.7273 - val_loss: 1.2154 - val_acc: 0.4286\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4704 - acc: 0.7273 - val_loss: 1.1695 - val_acc: 0.5714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.3999 - acc: 0.7727 - val_loss: 1.1590 - val_acc: 0.5714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.3918 - acc: 0.8636 - val_loss: 1.1992 - val_acc: 0.5714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.3703 - acc: 0.8182 - val_loss: 1.3162 - val_acc: 0.5714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.3180 - acc: 0.8636 - val_loss: 1.4996 - val_acc: 0.4286\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.3245 - acc: 0.9091 - val_loss: 1.6006 - val_acc: 0.4286\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.3280 - acc: 0.9545 - val_loss: 1.5720 - val_acc: 0.5714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3151 - acc: 0.8182 - val_loss: 1.5847 - val_acc: 0.5714\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3646 - acc: 0.9091 - val_loss: 1.6122 - val_acc: 0.5714\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.4184 - acc: 0.8182 - val_loss: 1.7085 - val_acc: 0.5714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.3008 - acc: 0.9545 - val_loss: 1.7902 - val_acc: 0.4286\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2864 - acc: 0.9091 - val_loss: 1.9158 - val_acc: 0.4286\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.3974 - acc: 0.7727 - val_loss: 1.7546 - val_acc: 0.4286\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.2932 - acc: 0.8636 - val_loss: 1.6229 - val_acc: 0.5714\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.3202 - acc: 0.8636 - val_loss: 1.5343 - val_acc: 0.5714\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.2608 - acc: 0.8636 - val_loss: 1.5519 - val_acc: 0.5714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.2122 - acc: 0.9545 - val_loss: 1.6147 - val_acc: 0.5714\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1848 - acc: 1.0000 - val_loss: 1.7164 - val_acc: 0.4286\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1742 - acc: 1.0000 - val_loss: 1.8200 - val_acc: 0.4286\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.2914 - acc: 0.8636 - val_loss: 1.8105 - val_acc: 0.5714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.1928 - acc: 0.9091 - val_loss: 1.7989 - val_acc: 0.5714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2118 - acc: 0.9545 - val_loss: 1.8286 - val_acc: 0.5714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2093 - acc: 0.9545 - val_loss: 1.9826 - val_acc: 0.5714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.2247 - acc: 0.9091 - val_loss: 2.2220 - val_acc: 0.4286\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1890 - acc: 0.9545 - val_loss: 2.3058 - val_acc: 0.4286\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1957 - acc: 0.9091 - val_loss: 2.1970 - val_acc: 0.4286\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.2055 - acc: 0.9545 - val_loss: 2.0396 - val_acc: 0.4286\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1680 - acc: 0.9091 - val_loss: 1.9787 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1328 - acc: 0.9545 - val_loss: 1.9305 - val_acc: 0.5714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.2263 - acc: 0.9545 - val_loss: 2.0227 - val_acc: 0.4286\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.1722 - acc: 0.9545 - val_loss: 2.0996 - val_acc: 0.4286\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2111 - acc: 0.9091 - val_loss: 2.1356 - val_acc: 0.4286\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1363 - acc: 0.9545 - val_loss: 2.1922 - val_acc: 0.4286\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1599 - acc: 0.9545 - val_loss: 1.9560 - val_acc: 0.5714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.1725 - acc: 0.9545 - val_loss: 1.9359 - val_acc: 0.4286\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.1573 - acc: 0.9091 - val_loss: 1.9002 - val_acc: 0.2857\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.2342 - acc: 0.9091 - val_loss: 2.0046 - val_acc: 0.5714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.1166 - acc: 0.9545 - val_loss: 2.3661 - val_acc: 0.4286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1884 - acc: 0.9545 - val_loss: 2.5445 - val_acc: 0.4286\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.2947 - acc: 0.8636 - val_loss: 2.2905 - val_acc: 0.5714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2176 - acc: 0.9091 - val_loss: 2.0249 - val_acc: 0.5714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0867 - acc: 0.9545 - val_loss: 1.9003 - val_acc: 0.5714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1056 - acc: 1.0000 - val_loss: 1.8955 - val_acc: 0.4286\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1176 - acc: 0.9545 - val_loss: 1.9371 - val_acc: 0.5714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1076 - acc: 1.0000 - val_loss: 2.0541 - val_acc: 0.5714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1369 - acc: 0.9091 - val_loss: 2.2479 - val_acc: 0.4286\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1256 - acc: 0.9545 - val_loss: 2.3372 - val_acc: 0.4286\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0790 - acc: 0.9545 - val_loss: 2.3529 - val_acc: 0.4286\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1631 - acc: 0.9545 - val_loss: 2.3400 - val_acc: 0.4286\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0390 - acc: 1.0000 - val_loss: 2.3286 - val_acc: 0.5714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1272 - acc: 0.9091 - val_loss: 2.3547 - val_acc: 0.5714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1317 - acc: 0.9091 - val_loss: 2.4321 - val_acc: 0.4286\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0771 - acc: 1.0000 - val_loss: 2.5071 - val_acc: 0.4286\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1095 - acc: 0.9545 - val_loss: 2.5413 - val_acc: 0.4286\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0705 - acc: 1.0000 - val_loss: 2.6046 - val_acc: 0.4286\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0715 - acc: 1.0000 - val_loss: 2.6227 - val_acc: 0.4286\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1007 - acc: 0.9545 - val_loss: 2.5803 - val_acc: 0.5714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.1150 - acc: 0.9091 - val_loss: 2.5734 - val_acc: 0.5714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0903 - acc: 0.9545 - val_loss: 2.6402 - val_acc: 0.5714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0625 - acc: 0.9545 - val_loss: 2.7042 - val_acc: 0.5714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1126 - acc: 0.9545 - val_loss: 2.8603 - val_acc: 0.5714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1023 - acc: 0.9091 - val_loss: 3.0191 - val_acc: 0.5714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0825 - acc: 0.9545 - val_loss: 3.1127 - val_acc: 0.4286\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 3.2291 - val_acc: 0.4286\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0937 - acc: 0.9545 - val_loss: 3.3115 - val_acc: 0.4286\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0961 - acc: 0.9545 - val_loss: 3.3956 - val_acc: 0.4286\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 3.4855 - val_acc: 0.4286\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0830 - acc: 0.9545 - val_loss: 3.4087 - val_acc: 0.4286\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1408 - acc: 0.9091 - val_loss: 3.3106 - val_acc: 0.5714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0317 - acc: 1.0000 - val_loss: 3.2897 - val_acc: 0.5714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0547 - acc: 1.0000 - val_loss: 3.3740 - val_acc: 0.5714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0444 - acc: 1.0000 - val_loss: 3.4665 - val_acc: 0.5714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 3.5848 - val_acc: 0.5714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0792 - acc: 0.9545 - val_loss: 3.7474 - val_acc: 0.4286\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1660 - acc: 0.9091 - val_loss: 3.7972 - val_acc: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15746d5af98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch=None, epochs=100, verbose=1, callbacks=None, validation_data=test_set, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x157473CF048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/hp/Desktop/btd1_project/TestImages/f3cdd4e71aaab8707bd4639e98b9bc.jpg', target_size = (64, 64))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[2., 2., 2.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[4., 4., 4.],\n",
       "         [1., 1., 1.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Benign': 0, 'Malignant': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected tumor type is Benign\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 0:\n",
    "    prediction = 'Benign'\n",
    "else:\n",
    "    prediction = 'Malignent'\n",
    "print(\"Detected tumor type is %s\"%prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
